<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>reveal.js</title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/black.css">
		<link rel="stylesheet" href="css/custom.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section data-markdown>
					##Modeling other minds:
					###A neuroengineering approach
					John Pearson

					[pearsonlab.github.io/duke-CCN-talk-2017](https://pearsonlab.github.io/duke-CCN-talk-2017)
				</section>
				<section data-background-image="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/macaques_group.jpg">
					<aside class="notes" data-markdown>
						photo credit: Buddhika Weerasinghe/Getty Images
					</aside>
				</section>
				<section data-background-image="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/4f.png">
					<aside class="notes" data-markdown>
						- [upper left](https://thedrinkingbird.files.wordpress.com/2013/05/img_2476.jpg)
						- [upper right](http://seancrane.com/galleries/japan/) Sean Crane
						- [lower right](http://www.gettyimages.com/license/153234629): MOHD RASFAN/AFP/GettyImages
						- [lower right](https://commons.wikimedia.org/wiki/File:Baviaan2.JPG) Dick Mudde
					</aside>
				</section>
				<section>
					<h3>A social brain?</h3>
					<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/mars_tpj.png" style="width: 75%">
					<p class="ref">Mars et al. (PNAS 2014)</p>
				</section>
				<section data-background-image="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/macaque_grooming.jpg">
					<h2>But how do you turn this...</h2>
					<aside class="notes" data-markdown>
					[photo credit](https://lucygoes.files.wordpress.com/2013/10/img_6986.jpg)
					</aside>
				</section>
				<section>
					<h3>...into <em>this?</em></h3>
					<div style="float:left; width:50%">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/fmri_activation.png" >
					</div>
					<div style="float:left; width:50%">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/gold_shadlen.png" >
					</div>
				</section>
				<section data-markdown>
					##You knew there was a catch
					- How far can we distill social interaction?
					- Trial averaging is out.
					- Our (statistical) models are limiting our thinking.
				</section>
				<section data-background-image="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/deep_learning_cover.jpg" data-background-size="contain">
				</section>
				<section data-markdown>
					### Today's plan:
					Social neuroscience from the outside in:
					- Learning "social space" from spiking ([arXiv](https://arxiv.org/abs/1512.01408))
					- Inferring goals from complex motions ([arXiv](https://arxiv.org/abs/1702.07319))
					- Single-trial analysis of neural spiking (in prep)
				</section>
				<section data-background-image="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/animatronic.jpg" data-background-size="contain">
					<blockquote cite="https://www.quora.com/What-did-Richard-Feynman-mean-when-he-said-What-I-cannot-create-I-do-not-understand", style="background-color: rgba(150, 150, 150, 0.75)">
					What I cannot create, I do not understand. &mdash; Richard Feynman
					</blockquote>
					<aside class="notes" data-markdown>
						# A note on method
						- this is what I mean by neuroengineering
							- *reverse* engineering
						- not sufficient, but necessary
						- trying to build it means understanding constraints
						- most interesting ideas in neuro theory about how *ANN*s learn

						### photo credit:
						[link](https://www.behance.net/gallery/26305123/ANIMATRONIC-AI-FOR-SPIELBERGS-EXTANT)
					</aside>
				</section>
				<section data-markdown>
					###A reverse engineering approach
					- Work "outside-in"
					- Focus on computational constraints
					- "Structured black box" modeling
				</section>
				<section>
					<h3>How do neurons see the world?</h3>
					<div style="float:left; width:25%">
						<p></p>
					</div>
					<div style="float:left; width:25%">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/gabor.jpg" >
					</div>
					<div style="float:left; width:25%">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/cartoon_faces.png" >
						<p class="ref">Freiwald, Tsao, Livingstone (<em>Nature Neuroscience</em>, 2009)</p>
					</div>
				</section>
				<section>
					<h3>But what if we use this?</h3>
					<video width="70%" align="center" controls autoplay loop src="https://web.duke.edu/mind/level2/faculty/pearson/assets/videos/etho/agonism.ogg" type="video/webm">
						Your browser does not support the video tag.
					</video>
					<p class="ref">Adams, Pearson, and Platt (in prep)</p>
				</section>
				<section>
					<div style="float:left; width:25%">
						<p></p>
					</div>
					<div style="float:left; width:25%">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/xin.jpg" >
						<p>Xin Chen</p>
					</div>
					<div style="float:left; width:25%">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/beck.jpg" >
						<p>Jeff Beck</p>
					</div>
					<div style="float:left; width:25%">
					</div>
				</section>
				<section>
					<h3>Let's run an experiment</h3>
					<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/nev/movie.svg" style="background: white">
				</section>
				<section>
					<h3>Let's imagine a model</h3>
					<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/nev/model_cartoon.svg" style="background: white">
				</section>
				<section data-markdown>
					###We are not the first
					- Gallant lab (fMRI) ([Huth 2012](http://www.sciencedirect.com/science/article/pii/S0896627312009348), [Stansbury 2013](http://www.sciencedirect.com/science/article/pii/S0896627313005503))
					- Continuous latent states ([Park 2014](http://www.nature.com/neuro/journal/v17/n10/abs/nn.3800.html), [Buesing 2014](http://papers.nips.cc/paper/5339-clustered-factor-analysis-of-multineuronal-spike-data), [Archer 2015](https://arxiv.org/abs/1511.07367), [Park 2015](http://papers.nips.cc/paper/5790-unlocking-neural-population-non-stationarities-using-hierarchical-dynamics-models))
					- Discrete latent states ([Escola 2011](http://www.mitpressjournals.org/doi/abs/10.1162/NECO_a_00118#.WNqSexLythE), [Putzky 2014](http://papers.nips.cc/paper/5338-a-bayesian-model-for-identifying-hierarchically-organised-states-in-neural-population-activity))
					- ...and many more
				</section>
				<section data-markdown>
					###So what's different?
					- Previous models: latents capture *internal* dynamics
						- latents can be driven by stimuli
						- but vary for presentations of the same stimulus
					- Our model: latents capture *stimulus* dynamics
						- each stimulus frame has a set of binary tags
						- tags follow a Hidden (semi-)Markov Model
						- latents are *the same* for repeated stim presentations
				</section>
				<section>
					<h3>Let's put that in math</h3>
					$$
					\begin{align}
					N_{tu} &\sim \mathrm{Poisson}(\Lambda_{tu}\cdot\theta) \\
					\theta &\sim \mathrm{Gamma}(s, s) \\
					\Lambda_{tu} &= \lambda_{0u}
					\prod_{k=1}^K (\lambda_{zuk})^{z_{tk}}
					\prod_{r=1}^R (\lambda_{xuk})^{x_{tr}}
					\end{align}
					$$

					<p>firing rate = baseline * latents * externals * noise</p>
				</section>
				<section>
					<h3>And in diagram form</h3>
					<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/nev/model_formal.svg" style="background: white">
				</section>
				<section data-markdown>
					###Model fitting
					We have $p(N|Z, \Theta)$

					$Z$: latent variables, $\Theta$: model parameters

					We want
					$$
					p(Z, \Theta | N) \propto p(N|Z, \Theta)\, p(Z) \, p(\Theta)
					$$

					But too hard to do Bayes' Rule exactly!
				</section>
				<section data-markdown>
					> Do you want the wrong answer to the right question or the right answer to the wrong question? I think you want the former.
					>
					> &mdash; David Blei
				</section>
				<section data-markdown>
					###Variational Bayesian (VB) Inference
					- Replace true posterior $p$ with *approximate* posterior $q$
					- Minimize "distance" $KL(q \Vert p)$ between actual and approximate posteriors
					- Same as maximizing the evidence lower bound (ELBO): $\log p(N)$
				</section>
				<section>
					<h3>Experiment I: Synthetic data</h3>
					<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/nev/synthetic.svg" style="background: white">
				</section>
				<section>
					<h3>Experiment II: Parietal Cortex</h3>
					<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/nev/roitman.svg" style="background: white; width:80%">
					<p class="ref">Roitman and Shadlen (<em>J. Neuro.</em>, 2002)</p>
				</section>
				<section>
					<h3>Experiment III: Temporal Cortex</h3>
					<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/nev/imgclust_web.svg" style="background: white; width:100%">
					<p class="ref">McMahon et al. (<em>PNAS</em>, 2014)</p>
					<p>Face, monkey, and body part cells!</p>
				</section>
				<section>
					<h3>Experiment III: Temporal Cortex</h3>
					<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/nev/imgclust_neurons.svg" style="background: white; width:100%">
				</section>
				<section>
					<h3>Experiment III: Temporal Cortex</h3>
					<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/nev/imgclust_sub_web.svg" style="background: white; width:100%">
					<p>Viewpoint selectivity!</p>
				</section>
				<section data-markdown>
					###What did we do?
					- Given spike counts, *what features drive firing?*
					- Multiply "tag" each stimulus frame
					- Model recovers features from even modest data sizes when signal is strong
					- Goal is to look for patterns that **suggest new experiments.**
				</section>
				<section>
					<h3>Mind reading 101</h3>
					<img src="http://www.wnd.com/files/2016/11/Trump-Romney-TW.jpg" >
				</section>
				<section>
					<div style="float:left; width:25%">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/sfn2016/shariq.jpg" >
						<p>Shariq Iqbal</p>
					</div>
					<div style="float:left; width:25%">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/sfn2016/cbdrucker.jpg" >
						<p>Caroline Drucker</p>
					</div>
					<div style="float:left; width:25%">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/sfn2016/jfg.jpg" >
						<p>Jean-Francois Gari&eacute;py</p>
					</div>
					<div style="float:left; width:25%">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/sfn2016/PlattMichael.jpg" >
						<p>Michael Platt</p>
					</div>
				</section>
				<section data-background-image="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/monkey_fruit_tower.jpg">
					<aside class="notes" data-markdown>
						### competition is everywhere
						- need to figure out what others' goals are
						- we infer goals from movement
							- Stanislavsky
					</aside>
				</section>
				<section data-background-image="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/sfn2016/chess.jpg">
					<aside class="notes" data-markdown>
						### Pros:
						- Well-studied, normative solutions

						### Cons:
						- Highly idealized, limited dynamics
						- Biologically aligned?
					</aside>
				</section>
				<section data-background-image="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/sfn2016/penalty-shot.jpg">
					<aside class="notes" data-markdown>
						- Doesn't matter if it's social
							- Requires anticipating another agent
						- Repeatable, but lots of variation
						- Decisions tightly linked to movement
					</aside>
				</section>
				<section>
					<h3>Penalty Shot</h3>
					<video width="70%" align="center" controls autoplay loop src="https://web.duke.edu/mind/level2/faculty/pearson/assets/videos/penaltyshot/sess130_new.mp4" type="video/mp4">
						Your browser does not support the video tag.
					</video>
					<aside class="notes" data-markdown>
					  - two monkeys, shooter and goalie (shooter recorded)
					  - controlled by joysticks
					  - roles rotated, animals know each other
					  - repeated sessions
					  - rapidly learned, rich dynamics
					</aside>
				</section>
				<section>
					<div style="width: 50%; float: left; text-align: left">
						<video autoplay loop  src="https://web.duke.edu/mind/level2/faculty/pearson/assets/videos/penaltyshot/real_trial.mp4" type="video/mp4" id="trace_video">
							Your browser does not support the video tag.
						</video>
						<script>
						var vid = document.getElementById("trace_video");
vid.playbackRate = 1.;
						</script>
					</div>
					<div style="width: 50%; float: right; font-size: .9em" >
						<h3>Complexity tax</h3>
						<ul style="font-size: 0.85">
							<li>each trial a different length</li>
							<li>how to average, align?</li>
							<li>need to "reduce" dynamics</li>
						</ul>
					</div>
				</section>
				<section>
					<h3>Real trials</h3>
					<div style="width: 50%; margin: auto">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/paper_figs/real_traces.svg" alt="">
					</div>
				</section>
				<section data-markdown>
					### Our approach
					- Borrow from control theory, time series
					- Structured black box models (pieces make sense)
					- Neural networks for flexible fitting
				</section>
				<section>
					<h3>Modeling I</h3>
					Observed positions at each time ($y_t$):

					$$
					y_t = \begin{bmatrix}
					y_{goalie} &
					x_{puck} &
					y_{puck}
					\end{bmatrix}^\top
					$$

					<br>
					Control inputs ($u_t$) drive changes in observed positions:
					$$y_{t + 1} = y_t + v_{max} \sigma(u_t)$$

					<br>
					<b>Goal</b>: predict control inputs from trial history:
					$$u_t = F(y_{1:t})$$
				</section>
				<section>
					<h3>Modeling II</h3>
					Assumption: PID control
					$$
					u_t = u_{t-1} + L * (g_t - y_{t-1}) + \epsilon_t
					$$
					<br>
					<ul>
					  <li>linear control model: $L$</li>
					  <li>goal (set point): $g_{t}$</li>
					  <li>error signal: $e_t \equiv g_{t} - y_{t-1}$</li>
					  <li>observation noise: $\epsilon_t$</li>
				  </ul>
				</section>
				<section>
					<h3>Modeling III</h3>
					<h5>Goal model:</h5>
					$$
					\log p(g) = -\beta E(g|s) - \log Z \\
					E(g|s) = \sum_t \left[ \frac{1}{2} \Vert g_t - g_{t-1}\Vert^2 + U(g_t, s_t)\right]
					$$
					<br>
					<h5>How do we interpret this?</h5>
					<ul>
						<li>Goals minimize an "energy"</li>
						<li>"Potential" $U$ captures player interaction</li>
					</ul>
				</section>
				<section>
					<h3>Modeling IV</h3>
					<ul>
						<li>$U$ is a problem</li>
						<li>What if $U$ were just quadratic?</li>
						<li>Model $e^U$ as a *mixture* of normals</li>
						<li>Use a Generative Adversarial Network</li>
					</ul>
				</section>
				<section>
					<h3>GANsplaining</h3>
					<div class="wrapper" style="">
						<img
						class="fragment fade-out"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/sfn2016/shariq.jpg"
						style="grid-column: 2/3; grid-row: 1/2"
						data-fragment-index="12">
						<img
						class="fragment fade-out"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/jmp_square.png"
						style="grid-column: 3/4; grid-row: 1/2"
						data-fragment-index="13">

						<!-- pop up item and response -->
						<div class="fragment fade-up" style="grid-column: 2/3; grid-row: 2/3" data-fragment-index="1">
							<div class="fragment fade-out" data-fragment-index="3">
								<img
								class="grid-img"
								src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/bad_dollar.jpg">
							</div>
						</div>
						<img
						class="fragment current-visible grid-img"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/red_x.png"
						style="grid-column: 3/4; grid-row: 2/3"
						data-fragment-index="2">

						<!-- pop up item and response -->
						<div class="fragment fade-up" style="grid-column: 2/3; grid-row: 2/3" data-fragment-index="4">
							<div class="fragment fade-out" data-fragment-index="6">
								<img
								class="grid-img"
								src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/wizard_lincoln.jpg">
							</div>
						</div>
						<img
						class="fragment current-visible grid-img"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/red_x.png"
						style="grid-column: 3/4; grid-row: 2/3"
						data-fragment-index="5">

						<!-- pop up item and response -->
						<div class="fragment fade-up" style="grid-column: 2/3; grid-row: 2/3" data-fragment-index="7">
							<div class="fragment fade-out" data-fragment-index="9">
								<img
								class="grid-img"
								src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/kiss_jackson.jpg">
							</div>
						</div>
						<img
						class="fragment current-visible grid-img"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/red_x.png"
						style="grid-column: 3/4; grid-row: 2/3"
						data-fragment-index="8">

						<!-- pop up item and response -->
						<div class="fragment fade-up" style="grid-column: 2/3; grid-row: 2/3" data-fragment-index="10">
							<div class="">
								<img
								class="grid-img"
								src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/dollar_bill.jpg">
							</div>
						</div>
						<img
						class="fragment fade-up grid-img"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/green_check.png"
						style="grid-column: 3/4; grid-row: 2/3"
						data-fragment-index="11">

						<!-- pop up ANN images (with captions)-->
						<div
						class="fragment fade-up"
						style="grid-column: 2/3; grid-row: 1/2"
						data-fragment-index="12" >
							<div>
								<img
								src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/neural_network.svg"
								style="background: white; vertical-align: bottom; margin-bottom: 0">
								<p style="vertical-align: top; margin: 0">Generator</p>
							</div>
						</div>
						<div
						class="fragment fade-up"
						style="grid-column: 3/4; grid-row: 1/2"
						data-fragment-index="13" >
							<div>
								<img
								src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/neural_network.svg"
								style="background: white; vertical-align: bottom; margin-bottom: 0">
								<p style="vertical-align: top; margin: 0">Discriminator</p>
							</div>
						</div>
					</div>

				</section>
				<section>
					<h3>Our model</h3>
					<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/paper_figs/model_diagram.svg" style="background:white">
				</section>
				<section>
					<h3>Model fitting</h3>
					<h5>Variational Bayes autoencoder</h5>
					<ul>
					<li>Encoding model:</li>
						<ul>
						<li>goals: cGAN</li>
						<li>control: PID + Gaussian noise</li>
						</ul>
					<br>
					<li>Decoding model:</li>
						<ul>
						<li>state space model <a href="https://arxiv.org/abs/1511.07367">(Archer et al., 2015)</a></li>
						<li>= Kalman filter for linear system</li>
						</ul>
					</ul>
				</section>
				<section>
					<h3>It fits!</h3>
					<div style="width: 50%; float: left; text-align: left">
						<img  src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/pos_fit.svg" style="border: none; background: none; box-shadow: none">
						</img>
					</div>
					<div style="width: 50%; float: right; text-align: left">
						<img  src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/paper_figs/single_trial_control.svg" style="border: none; background: none; box-shadow: none">
						</img>
					</div>
				</section>
				<section>
					<h3>Generated Trials</h3>
					<video width="70%" align="center" controls autoplay loop src="https://web.duke.edu/mind/level2/faculty/pearson/assets/videos/penaltyshot/gen_data.mp4" type="video/mp4">
						Your browser does not support the video tag.
					</video>
					<aside class="notes" data-markdown>
					  - Totally new behavior
					  - Captures some of the richness of original data
					  - Gives us confidence that our model is plausible
					  - *Much* stronger test than simple goodness-of-fit
					    - You can have a model that "fits" but the
						observed data are atypical of the model
					</aside>
				</section>
				<section>
					<h3>Generated trials</h3>
					<div style="width: 50%; float: left">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/paper_figs/real_traces.svg" alt="">
					</div>
					<div style="width: 50%; float: right">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/paper_figs/gen_traces.svg" alt="">
					</div>
				</section>
				<section>
					<h3>A sample trial</h3>
					<video width="70%" align="center" controls autoplay loop src="https://web.duke.edu/mind/level2/faculty/pearson/assets/videos/penaltyshot/real_trial.mp4" type="video/mp4">
						Your browser does not support the video tag.
					</video>
				</section>
				<section>
					<h3>Inferred goals</h3>
					<video width="70%" align="center" controls autoplay loop src="https://web.duke.edu/mind/level2/faculty/pearson/assets/videos/penaltyshot/real_trial_goals.mp4" type="video/mp4">
						Your browser does not support the video tag.
					</video>
				</section>
				<section>
					<h3>Value function</h3>
					<video width="70%" align="center" controls autoplay loop src="https://web.duke.edu/mind/level2/faculty/pearson/assets/videos/penaltyshot/real_trial_value.mp4" type="video/mp4">
						Your browser does not support the video tag.
					</video>
				</section>
				<section data-markdown>
					###What did we do?
					- Dynamic control tasks let us leverage motor behavior to study cognitive and social decisions.
					- Structured black-box models allow us to carve behavior into interpretable pieces.
					- We inferred a value function capable of explaining behavior in terms of goals.
				</section>
				<section>
					<h3>Predicting final target</h3>
					<div style="float: left; width: 50%">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/start_trial_end_predict.svg" alt="">
					</div>
					<div style="float: right; width: 50%">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/end_trial_end_predict.svg" alt="">
					</div>
				</section>
				</section>
				<section data-markdown>
					### Conclusions
					- Capturing social behavior in the lab is challening
					- But we can get traction by
						- working "outside-in": from sensory and motor to intermediate signals
						- leveraging rich models: matching our analyses to our questions
				</section>
				<section>
					<div class="wrapper" style="">
						<img
						class="grid-item"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/website/shariq.jpg"
						style="grid-column: 1/2; grid-row: 1/2">
						<img
						class="grid-item"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/website/xin.jpg"
						style="grid-column: 2/3">
						<img
						class="grid-item"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/website/abhishek.jpg"
						style="grid-column: 3/4">
						<img
						class="grid-item"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/website/athelia.jpg"
						style="grid-column: 4/5">
						<img
						class="grid-item"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/website/robert.jpg"
						style="grid-column: 1/2">
						<img
						class="grid-item"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/website/jeff.jpg"
						style="grid-column: 2/3">
						<img
						class="grid-item"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/website/andrew.jpg"
						style="grid-column: 3/4">
						<img
						class="grid-item"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/website/kelsey.jpg"
						style="grid-column: 4/5">
						<img
						class="grid-item"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/sfn2016/bd2k_logo.png"
						style="grid-column: 1/2; border: none; background: none; box-shadow: none">
						<img
						class="grid-item"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/lab_logo/plab_logo_light.svg"
						style="grid-column: 2/4">
						<img
						class="grid-item"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/sfn2016/US-NIH-NIMH-Logo.svg"
						style="grid-column: 4/5">
					</div>
				</section>


				<!-- extra slides -->

				<section>
					<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/etho_turn.png" alt="">
				</section>
				<section>
					<h3>Same behavior, different mechanisms</h3>
					<img  src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/marr.png" style="border: none; background: white; box-shadow: none">
					</img>
					<p class="ref">Adams, Watson, Pearson, and Platt (2012)</p>
				</section>
				<section>
					<h3>Foraging, for instance</h3>
					<img  src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/foraging.png" style="border: none; background: white; box-shadow: none">
					</img>
					<p class="ref">Pearson, Watson, and Platt (2014)</p>
				</section>
				<section>
					<div style="width: 50%; float: left">
						<ul>
							<li>Watch it</li>
							<li>Poke it</li>
							<li>BUILD IT</li>
						</ul>
					</div>
					<div style="width: 50%; float: right">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/terminator_monkey.jpg" alt="">
					</div>
				</section>
				<section>
					<h3>Probing the model</h3>
					<div style="width: 50%; float: left">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/paper_figs/init_both_down.svg" alt="">
					</div>
					<div style="width: 50%; float: right">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/paper_figs/init_goalieup_balldown.svg" alt="">
					</div>
				</section>
				<section>
					<h3>Initial goal distribution</h3>
					<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/paper_figs/g0_fit.svg" alt="">
				</section>
			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				history: true,
				// math: {
				//         mathjax: 'https://cdn.mathjax.org/mathjax/latest/MathJax.js',
				//         config: 'TeX-AMS_HTML-full'  // See http://docs.mathjax.org/en/latest/config-files.html
			    // },

				// More info https://github.com/hakimel/reveal.js#dependencies
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/math/math.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
